<u>AI Explained Simply : Sharing My Learnings</u>


 **AI would revolutionize search capabilities**  and  will enhance human understanding and questioning.
 AI enhances human curiosity by generating questions beyond our current understanding, It empowers users to ask questions confidently and receive trustworthy answers.
 
 **AI democratizes access to knowledge and answers for everyone** , It democratizes knowledge, igniting endless curiosity and question-asking potential.
 
**What is Generative AI (GenAI)?**

Generative AI refers to artificial intelligence systems that can create new content like:

Text (articles, blogs, reports)

Images (art, designs)

Code (programming help)

Music, videos, and more

**Examples: ChatGPT, Gemini, DALL¬∑E, Claude, GitHub Copilot.**

**Why is GenAI booming in the market?**

Massive productivity boost - It helps developers, marketers, analysts, and others do more in less time.

Democratization of creativity -  Anyone (even without special skills) can create high-quality content.

AI as an assistant-  Earlier AI was only predictive (e.g., forecasting sales)
Integration into products -  Big tech companies are adding GenAI into almost every software/tool we use.

**Top Benefits of GenAI**

Faster work -  Quickly creates content, code, and ideas.

Automation-  Takes over repetitive tasks using intelligence.

Personalized learning - Acts like a tutor/guide tailored to your needs.

Better customer service -  AI chatbots and agents can solve queries instantly.

**Concerns**

Data privacy -  Ensuring personal or company data isn‚Äôt misused.

Intellectual property (IP) -  Making sure the content created by AI doesn‚Äôt violate copyright or ownership.


**AI - How it is revolutionalising Software Development**

 AI can save huge amounts of time (days or weeks of work reduced to minutes) if you use it with the right workflows and prompts.

AI doesn‚Äôt replace a developer‚Äôs logic ‚Äî instead, it amplifies it.
Developers still need to analyze, guide, and verify AI outputs to make sure the results are reliable and not just ‚Äúquick hacks.‚Äù


AI is not magic ‚Äî it works on patterns, context, and the right usage.

Developers must learn prompt engineering (the skill of giving AI the right instructions).

AI should be treated as a partner, not a black box.

Always validate outputs just like reviewing a junior developer‚Äôs work.

Future of software engineering is not just writing code, but also knowing:

What tasks to delegate to AI,
How to instruct AI clearly,
When to step in manually.

**In short:**
AI helps us move faster, but true value comes from building smarter, reliable, and resilient systems by combining developer judgment with AI power.


 **AI TERMINOLOGIES** 

ùü≠. ùóüùóüùó† (ùóüùóÆùóøùó¥ùó≤ ùóüùóÆùóªùó¥ùòÇùóÆùó¥ùó≤ ùó†ùóºùó±ùó≤ùóπ) 

 Helps computers understand and write human-like text 
 LLM = the brain that generates text.
 
 Examples: GPT-4, Claude, Gemini 
 Used in: Chatbots, coding tools, content generation

ùüÆ. ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ 

The tech behind all modern AI models 
Let models understand meaning, context, and order of words 

Transformers = the architecture that makes LLMs powerful.

Examples: BERT, GPT

ùüØ. ùó£ùóøùóºùó∫ùóΩùòÅ ùóòùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥ 

 Writing better instructions to get better AI answers 
 Includes system prompts, step-by-step prompts, and safety rules

ùü∞. ùóôùó∂ùóªùó≤-ùóßùòÇùóªùó∂ùóªùó¥ 

Training an AI model on your data 
 Helps tailor it for specific tasks like legal, medical, or financial use cases

ùü±. ùóòùó∫ùóØùó≤ùó±ùó±ùó∂ùóªùó¥ùòÄ 

A way for AI to understand meaning and relationships between words or documents 
Used in search engines and recommendation systems

ùü≤. ùó•ùóîùóö (ùó•ùó≤ùòÅùóøùó∂ùó≤ùòÉùóÆùóπ-ùóîùòÇùó¥ùó∫ùó≤ùóªùòÅùó≤ùó± ùóöùó≤ùóªùó≤ùóøùóÆùòÅùó∂ùóºùóª) 

Combines AI with a database or document store 
Helps AI give more accurate, fact-based answers

RAG = a method to make LLMs smarter with external, real-time data.

ùü≥. ùóßùóºùó∏ùó≤ùóªùòÄ 

 The chunks of text AI reads and writes 
 Managing them controls cost and performance

 A token is the smallest unit of text that an LLM (like GPT) reads and understands.
 An LLM builds sentences by snapping these tokens together one by one.



ùó™ùóµùóÆùòÅ‚ÄôùòÄ  **Booming?**

‚Üí Multimodal AI (text, images, audio together) 
‚Üí Smaller, faster models 
‚Üí **Agentic AI (autonomous, task-completing agents)**




**What is an LLM?**

An LLM, or Large Language Model, is a type of neural network specifically
designed to process and generate human-like text. These models are built on
massive datasets, intricate architectures, and intensive training processes.
Here‚Äôs a simple formula to understand LLMs:

LLM = DATA + ARCHITECTURE + TRAINING

**Data**
LLMs are trained on petabytes of data. To give you an idea:
1 GB can contain around 178 million words.
1 PB (petabyte) equals 1 million GBS

This immense amount of data comes from various sources:
*Books
Transcripts
Web scraping*

**Architecture**

The architecture of LLMs, like GPT-4, is typically based on transformers.
Transformers are a type of model architecture that significantly advanced
the field by reducing training time and improving performance.

**Training**

Training involves feeding the data into the architecture and adjusting the
model based on its performance in predicting and generating text

**How Does an LLM Work?**
At its core, an LLM is a neural network trained on vast amounts of data to
recognize patterns in text. Here‚Äôs a breakdown of its key components:

1. **Tokenization:**
   
 The text is broken down into individual tokens. Tokens can
be single words or parts of words.

For example:
Single token: ‚ÄúHello‚Äù
Multi-token: *‚ÄúSummarization‚Äù -> ‚Äúsum‚Äù, ‚Äúmar‚Äù, ‚Äúization‚Äù*

2.**Embedding:**
   These tokens are then converted into vectors (1D
representations). This step helps the model understand the context and
relationships between words.

3. **Transformers:**
   Utilizing multi-head attention mechanisms, transformers
process these embeddings to predict and generate text. Transformers use
metrics like perplexity to measure how well the model predicts the next
word in a sequence.

**Applications of LLMs**

**LLMs are incredibly versatile and can be used for:**

**Summarization:** Condensing long texts into shorter summaries.

**Text Generation**Creating coherent and contextually relevant text.

**Creative Writing:** Assisting in generating stories, poems, and more.

**Q&A**Providing answers to questions based on the data they were trained
on.

**Programming:** Helping with code
‚Üí When AI gives wrong or made-up answers 
‚Üí Can be fixed with fact-checking and better prompts



**References :**  

https://www.geeksforgeeks.org/artificial-intelligence/what-is-artificial-intelligence-ai/

Google AI Blog: Keeps you updated on Google's latest research and developments in AI, often with accessible explanations.

https://ai.googleblog.com/

Podcasts on AI : 

Sam Altman x Nikhil Kamath
https://www.youtube.com/watch?v=SfOaZIGJ_gs


Nikhil Kamath x Nikesh Arora 

https://www.youtube.com/watch?v=vPvnzWoK24Q 


Aravind Srinivas Raj Shamani Podcast

https://www.youtube.com/watch?v=QY6yHJC2DIE
